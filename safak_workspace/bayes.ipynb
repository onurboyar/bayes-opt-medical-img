{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install bayesian-optimization\n!pip install git+https://github.com/aleju/imgaug.git","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:31:33.559996Z","iopub.execute_input":"2021-09-13T18:31:33.560324Z","iopub.status.idle":"2021-09-13T18:31:50.850713Z","shell.execute_reply.started":"2021-09-13T18:31:33.560245Z","shell.execute_reply":"2021-09-13T18:31:50.849384Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport cv2\nfrom torch.utils.data import RandomSampler, DataLoader, SequentialSampler, TensorDataset\nfrom tqdm.auto import tqdm\nimport logging\nfrom os import listdir\nfrom os.path import splitext\nfrom pathlib import Path\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nimport numpy as np\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torch import Tensor\nfrom torchvision import transforms\nfrom bayes_opt import BayesianOptimization\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:41:41.258401Z","iopub.execute_input":"2021-09-13T18:41:41.258749Z","iopub.status.idle":"2021-09-13T18:41:44.348507Z","shell.execute_reply.started":"2021-09-13T18:41:41.258711Z","shell.execute_reply":"2021-09-13T18:41:44.347675Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, images_dir: str, masks_dir: str, scale: float = 1.0, mask_suffix: str = '', transform = None):\n        self.images_dir = Path(images_dir)\n        self.masks_dir = Path(masks_dir)\n        assert 0 < scale <= 1, 'Scale must be between 0 and 1'\n        self.scale = scale\n        self.mask_suffix = mask_suffix\n        self.transform = transform\n\n        self.ids = [splitext(file)[0] for file in listdir(images_dir) if not file.startswith('.')]\n        if not self.ids:\n            raise RuntimeError(f'No input file found in {images_dir}, make sure you put your images there')\n        logging.info(f'Creating dataset with {len(self.ids)} examples')\n\n    def __len__(self):\n        return len(self.ids)\n\n    @classmethod\n    def preprocess(cls, pil_img, scale, is_mask):\n        w, h = pil_img.size\n        newW, newH = int(scale * w), int(scale * h)\n        assert newW > 0 and newH > 0, 'Scale is too small, resized images would have no pixel'\n        pil_img = pil_img.resize((newW, newH))\n        img_ndarray = np.asarray(pil_img)\n\n        if img_ndarray.ndim == 2 and not is_mask:\n            img_ndarray = img_ndarray[np.newaxis, ...]\n        elif not is_mask:\n            img_ndarray = img_ndarray.transpose((2, 0, 1))\n\n        if not is_mask:\n            img_ndarray = img_ndarray / 255\n            \n        if is_mask:\n            img_ndarray = img_ndarray / 255\n\n        return img_ndarray\n\n    @classmethod\n    def load(cls, filename):\n        ext = splitext(filename)[1]\n        if ext in ['.npz', '.npy']:\n            return Image.fromarray(np.load(filename))\n        elif ext in ['.pt', '.pth']:\n            return Image.fromarray(torch.load(filename).numpy())\n        else:\n            return Image.open(filename)\n\n    def __getitem__(self, idx):\n        name = self.ids[idx]\n        mask_file = list(self.masks_dir.glob(name + self.mask_suffix + '.*'))\n        img_file = list(self.images_dir.glob(name + '.*'))\n\n        assert len(mask_file) == 1, f'Either no mask or multiple masks found for the ID {name}: {mask_file}'\n        assert len(img_file) == 1, f'Either no image or multiple images found for the ID {name}: {img_file}'\n        mask = self.load(mask_file[0])\n        img = self.load(img_file[0])\n        \n\n        assert img.size == mask.size, \\\n            'Image and mask {name} should be the same size, but are {img.size} and {mask.size}'\n\n        img = self.preprocess(img, self.scale, is_mask=False)\n        mask = self.preprocess(mask, self.scale, is_mask=True)\n        \n        img = np.pad(img, ((0,0),(0,1),(0,0)), 'constant') # 1 pixel padding xd\n        mask = np.pad(mask, ((0,1),(0,0)), 'constant') # 1 pixel padding xd\n\n        if self.transform != None:\n            img, mask = self.transform((img, mask))\n\n        return {\n            'image': torch.as_tensor(img.copy()).float().contiguous(),\n            'mask': torch.as_tensor(mask.copy()).long().contiguous(),\n            'filename': str(mask_file[0]).split(\"/\")[-1]\n        }","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:41:57.613649Z","iopub.execute_input":"2021-09-13T18:41:57.613989Z","iopub.status.idle":"2021-09-13T18:41:57.632658Z","shell.execute_reply.started":"2021-09-13T18:41:57.613955Z","shell.execute_reply":"2021-09-13T18:41:57.631777Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n\n        # if bilinear, use the normal convolutions to reduce the number of channels\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        # input is CHW\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024 // factor)\n        self.up1 = Up(1024, 512 // factor, bilinear)\n        self.up2 = Up(512, 256 // factor, bilinear)\n        self.up3 = Up(256, 128 // factor, bilinear)\n        self.up4 = Up(128, 64, bilinear)\n        self.outc = OutConv(64, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:41:58.771855Z","iopub.execute_input":"2021-09-13T18:41:58.772263Z","iopub.status.idle":"2021-09-13T18:41:58.791746Z","shell.execute_reply.started":"2021-09-13T18:41:58.772222Z","shell.execute_reply":"2021-09-13T18:41:58.790904Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from torch import Tensor\n\ndef dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n    # Average of Dice coefficient for all batches, or for a single mask\n    assert input.size() == target.size()\n    if input.dim() == 2 and reduce_batch_first:\n        raise ValueError(f'Dice: asked to reduce batch but got tensor without batch dimension (shape {input.shape})')\n\n    if input.dim() == 2 or reduce_batch_first:\n        inter = torch.dot(input.contiguous().view(-1), target.contiguous().view(-1))\n        sets_sum = torch.sum(input) + torch.sum(target)\n        if sets_sum.item() == 0:\n            sets_sum = 2 * inter\n\n        return (2 * inter + epsilon) / (sets_sum + epsilon)\n    else:\n        # compute and average metric for each batch element\n        dice = 0\n        for i in range(input.shape[0]):\n            dice += dice_coeff(input[i, ...], target[i, ...])\n        return dice / input.shape[0]\n\ndef dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):\n    # Dice loss (objective to minimize) between 0 and 1\n    assert input.size() == target.size()\n    fn = multiclass_dice_coeff if multiclass else dice_coeff\n    return 1 - fn(input, target, reduce_batch_first=True)\n\ndef multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n    # Average of Dice coefficient for all classes\n    assert input.size() == target.size()\n    dice = 0\n    for channel in range(input.shape[1]):\n        dice += dice_coeff(input[:, channel, ...], target[:, channel, ...], reduce_batch_first, epsilon)\n\n    return dice / input.shape[1]\n\ndef evaluate(net, dataloader, device, disable=True):\n    net.eval()\n    num_val_batches = len(dataloader)\n    dice_score = 0\n\n    # iterate over the validation set\n    for batch in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', leave=False, position=0, disable=disable):\n        image, mask_true = batch['image'], batch['mask']\n        # move images and labels to correct device and type\n        image = image.to(device=device, dtype=torch.float32)\n        mask_true = mask_true.to(device=device, dtype=torch.long)\n        mask_true = F.one_hot(mask_true, net.n_classes).permute(0, 3, 1, 2).float()\n\n        with torch.no_grad():\n            # predict the mask\n            mask_pred = net(image)\n\n            # convert to one-hot format\n            if net.n_classes == 1:\n                mask_pred = (F.sigmoid(mask_pred) > 0.5).float()\n                # compute the Dice score\n                dice_score += dice_coeff(mask_pred, mask_true, reduce_batch_first=False)\n            else:\n                mask_pred = F.one_hot(mask_pred.argmax(dim=1), net.n_classes).permute(0, 3, 1, 2).float()\n                # compute the Dice score, ignoring background\n                dice_score += multiclass_dice_coeff(mask_pred[:, 1:, ...], mask_true[:, 1:, ...], reduce_batch_first=False)\n\n            \n    return dice_score / num_val_batches","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:41:59.389335Z","iopub.execute_input":"2021-09-13T18:41:59.389642Z","iopub.status.idle":"2021-09-13T18:41:59.405644Z","shell.execute_reply.started":"2021-09-13T18:41:59.389615Z","shell.execute_reply":"2021-09-13T18:41:59.404515Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torchvision\nimport random\n\nMAX_VALUES_BY_DTYPE = {\n    np.dtype(\"uint8\"): 255,\n    np.dtype(\"uint16\"): 65535,\n    np.dtype(\"uint32\"): 4294967295,\n    np.dtype(\"float32\"): 1.0,\n    np.dtype(\"float64\"): 1.0,\n}\n\ndef to_tuple(param, low=None, bias=None):\n    if low is not None and bias is not None:\n        raise ValueError(\"Arguments low and bias are mutually exclusive\")\n    if param is None:\n        return param\n    if isinstance(param, (int, float)):\n        if low is None:\n            param = -param, +param\n        else:\n            param = (low, param) if low < param else (param, low)\n    elif isinstance(param, Sequence):\n        param = tuple(param)\n    else:\n        raise ValueError(\"Argument param must be either scalar (int, float) or tuple\")\n    if bias is not None:\n        return tuple(bias + x for x in param)\n    return tuple(param)\n\nclass Gamma():\n    def __init__(self, gamma):\n        self.gamma = gamma\n        self.to_mask = False\n        self.to_img = True\n    \n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            if img.dtype == np.uint8:\n                table = (np.arange(0, 256.0 / 255, 1.0 / 255) ** self.gamma) * 255\n                img = cv2.LUT(img, table.astype(np.uint8))\n            else:\n                img = np.power(img, self.gamma)\n        if self.to_mask:\n            raise NotImplementedError()\n\n        return img, mask\n\nclass GaussianBlur():\n    def __init__(self, kernel_size, sigma_min=0.1, sigma_max=2.0):\n        self.sigma_min = sigma_min\n        self.sigma_max = sigma_max\n        self.kernel_size = kernel_size\n        self.to_mask = False\n        self.to_img = True\n\n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            sigma = np.random.uniform(self.sigma_min, self.sigma_max)\n            img = cv2.GaussianBlur(np.squeeze(img,axis=0), (self.kernel_size, self.kernel_size), sigma)\n            img = img[None, :, :]\n        if self.to_mask:\n            raise NotImplementedError()\n        return img, mask\n\nclass OpticalDistortion():\n    def __init__(self, k=0, dx=0, dy=0, interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_REFLECT_101, value=None):\n        self.k = k\n        self.dx = dx\n        self.dy = dy\n        self.interpolation = interpolation\n        self.border_mode = border_mode\n        self.value = value\n        self.to_mask = True\n        self.to_img = True\n    \n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            height, width = img.shape[-2], img.shape[-1]\n            fx = width\n            fy = height\n\n            cx = width * 0.5 + self.dx\n            cy = height * 0.5 + self.dy\n\n            camera_matrix = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=np.float32)\n\n            distortion = np.array([self.k, self.k, 0, 0, 0], dtype=np.float32)\n            map1, map2 = cv2.initUndistortRectifyMap(camera_matrix, distortion, None, None, (width, height), cv2.CV_32FC1)\n\n            img = cv2.remap(img, map1, map2, interpolation=self.interpolation, borderMode=self.border_mode, borderValue=self.value)\n        \n        if self.to_mask:\n            height, width = mask.shape[-2], mask.shape[-1]\n            fx = width\n            fy = height\n\n            cx = width * 0.5 + self.dx\n            cy = height * 0.5 + self.dy\n\n            camera_matrix = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=np.float32)\n\n            distortion = np.array([self.k, self.k, 0, 0, 0], dtype=np.float32)\n            map1, map2 = cv2.initUndistortRectifyMap(camera_matrix, distortion, None, None, (width, height), cv2.CV_32FC1)\n\n            mask = cv2.remap(mask, map1, map2, interpolation=self.interpolation, borderMode=self.border_mode, borderValue=self.value)\n        \n        return img, mask\n\nclass GaussianNoise():\n    def __init__(self, mu = 0, var_limit=(10.0, 50.0)):\n        self.mu = mu\n        self.var_limit = var_limit\n        self.to_mask = False\n        self.to_img = True\n\n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            height, width = img.shape[-2], img.shape[-1]\n            var = random.uniform(self.var_limit[0], self.var_limit[1])\n            sigma = var ** 0.5\n            random_state = np.random.RandomState(random.randint(0, 2 ** 32 - 1))\n            noise = random_state.normal(self.mu, sigma, (height, width))\n            img = (np.squeeze(img, axis = 0) + noise)[None, :, :]\n\n        if self.to_mask:\n            raise NotImplementedError()\n        \n        return img, mask\n\n\nclass GaussianNoiseDeterministic():\n    def __init__(self, var = 1):\n        self.mu = 0\n        self.var = var\n        self.to_mask = False\n        self.to_img = True\n\n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            height, width = img.shape[-2], img.shape[-1]\n            sigma = self.var ** 0.5\n            random_state = np.random.RandomState(random.randint(0, 2 ** 32 - 1))\n            noise = random_state.normal(self.mu, sigma, (height, width))\n            img = (np.squeeze(img, axis = 0) + noise)[None, :, :]\n\n        if self.to_mask:\n            raise NotImplementedError()\n        \n        return img, mask\n\nclass BrightnessContrast():\n    def __init__(self, brightness_limit=0.2, contrast_limit=0.2, brightness_by_max=True, always_apply=False, p=0.5):\n        self.brightness_limit = to_tuple(brightness_limit)\n        self.contrast_limit = to_tuple(contrast_limit)\n        self.brightness_by_max = brightness_by_max\n        self.to_mask = False\n        self.to_img = True\n\n    def __call__(self, pairs, alpha=None, beta=None):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            if alpha == None:\n                alpha = 1.0 + random.uniform(self.contrast_limit[0], self.contrast_limit[1]),\n            if beta == None:\n                beta = 0.0 + random.uniform(self.brightness_limit[0], self.brightness_limit[1])\n            img = np.squeeze(img, axis = 0)\n\n            if img.dtype == np.uint8:\n                dtype = np.dtype(\"uint8\")\n                max_value = MAX_VALUES_BY_DTYPE[dtype]\n                lut = np.arange(0, max_value + 1).astype(\"float32\")\n                if alpha != 1:\n                    lut *= alpha\n                if beta != 0:\n                    if self.brightness_by_max:\n                        lut += beta * max_value\n                    else:\n                        lut += beta * np.mean(img)\n\n                lut = np.clip(lut, 0, max_value).astype(dtype)\n                img = cv2.LUT(img, lut)\n                img = img[None, :, :]\n\n            else:\n                dtype = img.dtype\n                img = img.astype(\"float32\")\n                if alpha != 1:\n                    img *= alpha\n                if beta != 0:\n                    if self.brightness_by_max:\n                        max_value = MAX_VALUES_BY_DTYPE[dtype]\n                        img += beta * max_value\n                    else:\n                        img += beta * np.mean(img)\n                img = img[None, :, :]\n\n        if self.to_mask:\n            raise NotImplementedError()\n\n        return img, mask\n\n\nclass Rotate():\n    def __init__(self, angle):\n        self.angle = angle\n        self.to_mask = True\n        self.to_img = True\n\n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            seq = iaa.Sequential([iaa.Rotate((self.angle))])\n            img = seq(images=img)\n        if self.to_mask:\n            seq = iaa.Sequential([iaa.Rotate((self.angle))])\n            mask = seq(images=mask)\n        return img, mask\n\nclass ShearY():\n    def __init__(self, shear_amount):\n        self.shear_amount = shear_amount\n        self.to_mask = True\n        self.to_img = True\n\n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            seq = iaa.Sequential([\n                iaa.ShearY((self.shear_amount)),\n            ])\n\n            img = seq(images=img)\n\n        if self.to_mask:\n            seq = iaa.Sequential([\n                iaa.ShearY((self.shear_amount)),\n            ])\n        \n            mask = seq(images=mask)\n        return img, mask\n\n\nclass ShearX():\n    def __init__(self, shear_amount):\n        self.shear_amount = shear_amount\n        self.to_mask = True\n        self.to_img = True\n\n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            seq = iaa.Sequential([\n                iaa.ShearX((self.shear_amount)),\n            ])\n\n            img = seq(images=img)\n\n        if self.to_mask:\n            seq = iaa.Sequential([\n                iaa.ShearX((self.shear_amount)),\n            ])\n        \n            mask = seq(images=mask)\n        return img, mask\n\nclass ShiftY():\n    def __init__(self, shift_amount):\n        self.shift_amount = shift_amount\n        self.to_mask = True\n        self.to_img = True\n\n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            seq = iaa.Sequential([\n                iaa.TranslateY(px=(self.shift_amount)),\n            ])\n\n            img = seq(images=img)\n\n        if self.to_mask:\n            seq = iaa.Sequential([\n                iaa.TranslateY(px=(self.shift_amount)),\n            ])\n        \n            mask = seq(images=mask)\n        return img, mask\n\nclass ShiftX():\n    def __init__(self, shift_amount):\n        self.shift_amount = shift_amount\n        self.to_mask = True\n        self.to_img = True\n\n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        if self.to_img:\n            seq = iaa.Sequential([\n                iaa.TranslateX(px=(self.shift_amount)),\n            ])\n\n            img = seq(images=img)\n\n        if self.to_mask:\n            seq = iaa.Sequential([\n                iaa.TranslateX(px=(self.shift_amount)),\n            ])\n        \n            mask = seq(images=mask)\n        return img, mask\n    \n    \nclass ZoomOut():\n    def __init__(self, zoom_amount):\n        self.zoom_amount = zoom_amount\n        self.to_mask = True\n        self.to_img = True\n        \n    def __call__(self, pairs):\n        img = pairs[0]\n        mask = pairs[1]\n        \n        if self.to_img:\n            seq = iaa.Sequential([\n                iaa.Affine(scale={\"x\": (self.zoom_amount), \"y\": (self.zoom_amount)})\n            ])\n            img = seq(images=img)\n            \n        if self.to_mask:\n            seq = iaa.Sequential([\n                iaa.Affine(scale={\"x\": (self.zoom_amount), \"y\": (self.zoom_amount)})\n            ])\n            mask = seq(images=mask)\n        return img, mask","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:42:00.227937Z","iopub.execute_input":"2021-09-13T18:42:00.228282Z","iopub.status.idle":"2021-09-13T18:42:00.284234Z","shell.execute_reply.started":"2021-09-13T18:42:00.228241Z","shell.execute_reply":"2021-09-13T18:42:00.283381Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import math\ndef roundup(x):\n    return int(math.ceil(x*100 / 10.0)) * 10\n        \n\nroundup(3)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:42:01.347105Z","iopub.execute_input":"2021-09-13T18:42:01.347480Z","iopub.status.idle":"2021-09-13T18:42:01.355390Z","shell.execute_reply.started":"2021-09-13T18:42:01.347446Z","shell.execute_reply":"2021-09-13T18:42:01.354372Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"300"},"metadata":{}}]},{"cell_type":"code","source":"## todo1: turn this chunk into a function \n## todo2: function should has parameters for augmentation techniques\n\n\nimport math\ndef roundup(x):\n    return int(math.ceil(x / 10.0)) * 10\n\ndef discrete_angle(x):\n    if x in range(0,30):\n        x = 30\n    elif x in range(30,60):\n        x = 60\n    elif x in range(60,90):\n        x = 90\n    elif x in range(90,120):\n        x = 120\n    elif x in range(120,150):\n        x = 150\n    elif x in range(150,180):\n        x = 180\n\n    return x\n\ndef discrete_angle_normalized(x):\n    return int(math.ceil(x*100 / 10.0)) * 10\n\ndef discrete_shift(x):\n    if x >=0:\n        x = 100\n    else:\n        x = -100\n    return x\n    \n\ndef get_augmentations(**params):\n    transform = transforms.Compose([\n        transforms.RandomApply([Rotate(params[\"angle\"])], p=0.1), #0.1\n        transforms.RandomApply([ShiftX(params[\"shift_x\"])], p=0.2), #0.2\n        transforms.RandomApply([ShiftY(params[\"shift_y\"])], p=0.2), #0.2\n        transforms.RandomApply([ZoomOut(params[\"zoom_amount\"])], p=0.3), #0.3\n        transforms.RandomApply([Gamma(params[\"gamma\"])], p=0.3) #0.3\n        #transforms.RandomApply([GaussianNoiseDeterministic(params[\"var\"])], p=0.2)\n    ])\n    return transform\n\ndef get_dataloaders(transform):\n    dir_img = Path('/kaggle/input/drivebayes/drive/train/images/')\n    dir_mask = Path('/kaggle/input/drivebayes/drive/train/labels/')\n\n    test_dir_img = Path('/kaggle/input/drivebayes/drive/test/images/')\n    test_dir_mask = Path('/kaggle/input/drivebayes/drive/test/labels/')\n\n    dataset = SegmentationDataset(dir_img, dir_mask, 1., transform=transform)\n    test_dataset = SegmentationDataset(test_dir_img, test_dir_mask, 1.)\n\n    train_dataloader = DataLoader(dataset, shuffle=True, batch_size = 3)\n    test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size = 3)\n    return train_dataloader, test_dataloader\n\n\n\ndef train_unet(**params):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = UNet(n_channels=1, n_classes=2, bilinear=True).to(device)\n    optimizer = torch.optim.Adam(model.parameters()) #default lr is 0.001\n    criterion = nn.CrossEntropyLoss()\n\n    epochs = 15\n\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1) #optional\n\n    params[\"angle\"] = discrete_angle_normalized(params[\"angle\"])\n    params[\"shift_x\"] = discrete_shift(params[\"shift_x\"])\n    params[\"shift_y\"] = discrete_shift(params[\"shift_y\"])\n    \n    transform = get_augmentations(**params)\n    train_dataloader, test_dataloader = get_dataloaders(transform)\n    best_dice = 0\n    total = len(train_dataloader) * epochs\n\n    with tqdm(total = total, desc='Training round', leave=False, position=0, ) as tt:\n        for epoch in range(epochs):\n            batch_count, train_loss = 0, 0\n            for step, batch in enumerate(train_dataloader):\n                model.train()\n                batch_count +=1\n                optimizer.zero_grad()\n                out = model(batch[\"image\"].to(device))\n\n                loss = criterion(out, batch[\"mask\"].long().to(device)) \\\n                    + dice_loss(\n                        F.softmax(out, dim=1).float(),\n                        F.one_hot(batch[\"mask\"].to(device), model.n_classes).permute(0, 3, 1, 2).float(),\n                        multiclass=True\n                )\n\n                loss.backward()\n                optimizer.step()\n                train_loss += loss.item()\n                tt.update()\n            val_score = evaluate(model, test_dataloader, device, True)\n            if val_score.item() > best_dice:\n                best_dice = val_score.item()\n            scheduler.step() #optional\n    #print(f\"Dice Score: \"+str(val_score.item()))\n    return best_dice","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:42:39.601861Z","iopub.execute_input":"2021-09-13T18:42:39.602365Z","iopub.status.idle":"2021-09-13T18:42:39.633062Z","shell.execute_reply.started":"2021-09-13T18:42:39.602315Z","shell.execute_reply":"2021-09-13T18:42:39.632272Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"pbounds = {\n    'angle': (0,2), \n    'shift_x': (-1,1), \n    'shift_y': (-1,1),\n    'zoom_amount': (0.5,0.9),\n    'gamma': (0.5,1.5)\n    \n}\n\noptimizer = BayesianOptimization(\n    f=train_unet,\n    pbounds=pbounds,\n    random_state=1,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:42:43.319469Z","iopub.execute_input":"2021-09-13T18:42:43.319790Z","iopub.status.idle":"2021-09-13T18:42:43.325358Z","shell.execute_reply.started":"2021-09-13T18:42:43.319758Z","shell.execute_reply":"2021-09-13T18:42:43.324523Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"optimizer.maximize(\n    init_points=15,\n    n_iter=15,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T18:42:45.904687Z","iopub.execute_input":"2021-09-13T18:42:45.905009Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"|   iter    |  target   |   angle   |   gamma   |  shift_x  |  shift_y  | zoom_a... |\n-------------------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training round:   0%|          | 0/105 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7146  \u001b[0m | \u001b[0m 0.834   \u001b[0m | \u001b[0m 1.22    \u001b[0m | \u001b[0m-0.9998  \u001b[0m | \u001b[0m-0.3953  \u001b[0m | \u001b[0m 0.5587  \u001b[0m |\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training round:   0%|          | 0/105 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2006dc4167f245609110d69733a7c773"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}